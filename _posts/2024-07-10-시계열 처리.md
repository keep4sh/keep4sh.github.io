---
title: Time Series 처리 입문
date: 2024-07-10 09:00:42 +09:00
categories: [시계열 처리]
tags: [Deep Learning, Study, Time Series Data]
use_math: true
---

이번 포스팅부터는 시계열 데이터 관련 내용을 작성할 에정이다.<br>
시계열 데이터의 관한 문제는 통제된 상태에서 수집되는 데이터일 때 Deep Learning이 역할 수행이 유용하다. 만약 외부요인의 영향을 많이 받는 상태의 데이터의 경우 Label 데이터에 대한 예측값이 변경될 수 있기 때문이다.
<br>
시계열 데이터를 생각할 때는 데이터의 한 축을 시간으로 보여야 한다. 예를 들어 주식 데이터라고 보았을 때 주가를 $y$축, 시간을 $x$축으로 놓고 보았을 떄 시계열 데이터처럼 진행하는 것이다.

<p align = center>주요 개념</p>
> Stochastic Process<br>
> Stationarity, Autocorrelation<br>
> AR, MA, ARMA, ARIMA Process<br>
<br>
<br>

# 1. Stochastic Process
 우리 어떤 존재를 하나 깔고 시작해보자. 세상의 모든 시계열 데이터는 그 데이터가 가질 수 있는 가상의 Distribution, 즉 가상의  분포가 있으며 그 분포에서 샘플링을 진행했을 때 나온 값을 우리의 시계열 데이터가 된다. **Stochastic Process는** 데이터, 변수가 시간의 흐름에 따라 변화하며 가지게될 값들의 집합이다.
 > x_t에 대한 분포가 존재.<br>
 > 해당 분포에서 x_t를 Sampling을 여러번 진행할 수 있으며<br>
 > 이 변수들간, Correlation을 가질 수 있으며, 이 분포에서는 평균과 분산을 표현할 수 있다.
# 2. Stationarity
 시계열 모델이 학습 시계열 데이터를 가지고 학습을 진행한다고 했을 때, 우리의 예측 데이터가 학습 데이터와 다른 통계적인 특징을 가진다고 한다면, 예측이 제대로 이루어 지지 않을 것이다. 이로 인해 사용하는 개념이 **Stationarity(정상성)** 다.
 우리의 Stochastic Process 안에서, 즉 시간에 따라서 각 변수들이 가지는 통계적 특징들이 일정하게 유지될 때 Stationary를 가진고 표현한다. 만약 시간의 흐름에 상관없이 Stochastic Process에서 추출한 시계열 데이터가 항상 같은 분포를 가질 때 Strong Sationary라고 표현한다. 하지만 현실적으로 존재하는 데이터가 이러한 기준을 맞추기는 불가능에 가깝다. 반대로 Stochastic Process에서 평균, 분산이 전혀 맞지 않는 데이터라고 한다면 Non-Stationarity라고 표현할 수 있다.<br>
 이러한 Non-Stationarity를 갖게 될 경우 우리가 모델이 아무리 학습을 진행하여도 미래의 관측값을 예측하는 것이 어려워진다. 이를 맞춰주기 위해 Scaling, Normalization 등을 통해서 맞춰주는 과정이 필요하다.

# 3. Forecasting
Time Series로 우리가 Deep Learning을 하는 이유는 무엇인가? 현재까지 쌓아온 과거의 데이터를 가지고 미래를 예측하는 것이 목표이다. 때문에 우리가 데이터를 학습하기 위해서, 또한 검정하기 위해서는 몇가지 사전 요건들이 필요하다.<br>
시계열 데이터를 통한 모델은 학습 데이터를 통해서 검증을 진행하고 검증된 데이터를 통해서 테스트 데이터를 예측하여야 한다. 때문에 학습 데이터가 가장 과거, 검증 데이터, 테스트 데이터 순으로 데이터를 구분해두어야 한다. 이제 우린 학습 데이터를 모델에 넣어주어야 하는데 학습 데이터에 설정된 기간을 전부 학습 시키지 않는다. 모델에 넣어줄 구간, 모델이 예측할 구간을 따로 따로 설정해서 모델에 학습 시켜야 한다.<br><br>
학습 데이터의 일정 구간을 X_train, 그 외 구간을 X_val로 학습하는 것이다. 이후 검증 데이터에서도 마찬가지로 일정 구간을 y_train으로 모델이 학습을 진행, 그 외 구간을 통해서 y_val을 만들고 이를 통해 모델의 Loss를 확인. 마지막으로 테스트 데이터에서 진행한다.
<br><br>
또 한가지 우리가 생각해야할 부분은 단순히 우리의 데이터만을 벡터화 시켜서 학습 시키지 않고 시간 데이터 부분도 Embedding 하여서 학습 시켜줘야 한다. 이렇게 시간 데이터를 Embedding 하였다면 해당 위치 정보를 담고 있는 데이터를 형성, 이를 Embedding 해주어야 한다.
이렇게 총 3가지 Embedding Vector가 등장한다. Data를 담고 있는 Vector, 시간을 담고 있는 Vector, 위치 정보를 담고 있는 Vector.
이 3 Vector를 모두 더한 Vector를 Input으로 하여 Transformer에 학습 시킨다. 이 과정에서 Self-attemtion을 사용한다.